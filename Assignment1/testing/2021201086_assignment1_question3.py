# -*- coding: utf-8 -*-
"""2021201086_Assignment1_Question3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1edcmDgUzBB0fXwCsUzmjxTG81ig-m8hb

## Spam Email Classifier with KNN using TF-IDF scores

1.   Assignment must be implemented in Python 3 only.
2.   You are allowed to use libraries for data preprocessing (numpy, pandas, nltk etc) and for evaluation metrics, data visualization (matplotlib etc.).
3.   You will be evaluated not just on the overall performance of the model and also on the experimentation with hyper parameters, data prepossessing techniques etc.
4.   The report file must be a well documented jupyter notebook, explaining the experiments you have performed, evaluation metrics and corresponding code. The code must run and be able to reproduce the accuracies, figures/graphs etc.
5.   For all the questions, you must create a train-validation data split and test the hyperparameter tuning on the validation set. Your jupyter notebook must reflect the same.
6.   Strict plagiarism checking will be done. An F will be awarded for plagiarism.

**Task: Given an email, classify it as spam or ham**

Given input text file ("emails.txt") containing 5572 email messages, with each row having its corresponding label (spam/ham) attached to it.

This task also requires basic pre-processing of text (like removing stopwords, stemming/lemmatizing, replacing email_address with 'email-tag', etc..).

You are required to find the tf-idf scores for the given data and use them to perform KNN using Cosine Similarity.

### Import necessary libraries
"""

import pandas as pd
import numpy as np
import matplotlib as plt
import string
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem.wordnet import WordNetLemmatizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

import nltk
#nltk.download('punkt')
#nltk.download('stopwords')
#nltk.download('wordnet')

"""### Load Dataset"""

# Commented out IPython magic to ensure Python compatibility.
#from google.colab import drive
#drive.mount('/content/drive')
# %cd /content/drive/My Drive/smai/
data=pd.read_csv('emails.txt',sep='\t',header=None)
data.columns=['type','text']
data

data.drop_duplicates()
data

"""### Preprocess data"""

#removing punctuations
punctuations=string.punctuation
stop_words=stopwords.words('english')
def remove_punctuations(text):
  return ''.join(c for c in text if c not in punctuations)
#removing stopwords
wn = WordNetLemmatizer()
data['text'] = data['text'].apply(remove_punctuations)
data['text'] = data['text'].apply(word_tokenize)
data['text'] = data['text'].apply(lambda x: ([word.lower() for word in x if word not in stop_words]))
#Lemmatizing
data['text'] = data['text'].apply(lambda x: [wn.lemmatize(word) for word in x])

data.sample(10)

data=data[data['text'].map(lambda d: len(d)) > 0]
data.shape

"""#### Implementing TF-IDF Operations:
1. Create a set of unique words
2. Create an index of unique words 
3. 
"""

#unique words
"""
unique_words=set()
total_sentences=0
for text in data['text']:
  unique_words=unique_words.union(set(text))
  total_sentences+=1
index_unique_words={}
index=0
for word in unique_words:
  index_unique_words[word]=index
  index+=1
word_dict_list=[] # no. of occurences of a word in a sentence
size_list=[]
for text in data['text']:
  word_dict = dict.fromkeys(unique_words, 0)
  for word in text:
    word_dict[word]+=1
  word_dict_list.append(email_dict)
  size_list.append(len(text))
"""



#occurence of word in sentences
"""
doc_word_count=dict.fromkeys(unique_words, 0)
for text in data['text']:
  for word in unique_words:
    if word in text:
      doc_word_count[word]+=1
"""

#len(doc_word_count)

def term_freq(sentence, word):
    N = len(sentence)
    freq = len([x for x in sentence if x==word])
    return freq/float(N)

def inverse_doc_freq(word,doc_word_count,total_sentences):
    doc_freq = doc_word_count[word] + 1
    return np.log(total_sentences/float(doc_freq))

def tf_idf(sentence,doc_word_count,index_unique_words,unique_words,total_sentences):
    tf_idf_vector = np.zeros((len(unique_words),))
    for word in sentence:
      tf = term_freq(sentence,word)
      idf = inverse_doc_freq(word,doc_word_count,total_sentences)
      value = tf*idf
      tf_idf_vector[index_unique_words[word]] = value 
    return tf_idf_vector

def build_unique_words(data_frame_col):
  unique_words=set()
  for text in data_frame_col:
    unique_words=unique_words.union(set(text))
  return unique_words
def build_doc_freq(data_frame_col,unique_words):
  doc_word_count=dict.fromkeys(unique_words, 0)
  for text in data_frame_col:
    for word in unique_words:
      if word in text:
        doc_word_count[word]+=1
  return doc_word_count
def calc_tf_idf(data_frame_col):
  total_sentences=len(data_frame_col)
  unique_words=build_unique_words(data_frame_col)
  #for calculation of document freq:
  doc_word_count=build_doc_freq(data_frame_col,unique_words)
  index_unique_words={}
  index=0
  for word in unique_words:
    index_unique_words[word]=index
    index+=1
  vectors=[]
  for sentence in data_frame_col:
    tf_idf_vector = tf_idf(sentence,doc_word_count,index_unique_words
                             ,unique_words,total_sentences)
    vectors.append(tf_idf_vector)
  return vectors,index_unique_words
#labels=data['type']
vectors,index_unique_words=calc_tf_idf(data['text'])
#test_data=data['text'].sample(10)
#vectors,index_dict=calc_tf_idf(test_data)
print(vectors)
print(index_unique_words)
#test_data



"""### Split data"""

labels_train, labels_test, vectors_train, vectors_test = train_test_split(labels, vectors, test_size=0.05, random_state=42)

print(len(labels_test))
print(len(labels_train))

"""### Train your KNN model (reuse previously iplemented model built from scratch) and test on your data

***1. Experiment with different distance measures [Euclidean distance, Manhattan distance, Hamming Distance] and compare with the Cosine Similarity distance results.***
"""

#Calculating cosine similarity
def cosine_similarity(vector_a,vector_b):
  dot_product=np.dot(vector_a, vector_b)
  mag_a=np.linalg.norm(vector_a)
  mag_b=np.linalg.norm(vector_b)
  return (dot_product/(mag_a*mag_b))
cosine_similarity([1,2,3,0],[0,3,1,0])

def get_class(selected_Kvalues):
    spam_count = 0
    ham_count = 0
    # Counts the frequency of each class in K nearest neighbours
    for value in selected_Kvalues:
        if value[0] == "spam":
            spam_count += 1
        else:
            ham_count += 1
    if spam_count > ham_count:
        return "spam"
    else:
        return "ham"

def neighbors(query_vector,k,train_data):
    """ returns an iterable object (like list or generator) """
    # list of tuples of distances and corresponding user attached
    top_k_values=[]
    distances=[]
    for i in range(len(train_data)):
      distance=cosine_similarity(query_vector,train_data[i])
      distances.append((distance,i))
    top_k_indexes=[]
    distances.sort()
    for i  in distances[:k]:
      top_k_indexes.append(i[1])
    return top_k_indexes

def k_nearest_neighbours(k,train_data,train_labels,test_data):
  test_labels=[]
  for i in range(len(test_data)):
    k_nearest=neighbors(test_data[i],k,train_data)
    k_labels=[]
    for index in k_nearest:
      k_labels.append(train_labels[index])
      print(k_nearest)
    test_labels.append(get_class(k_labels))
  return test_labels
k_values=[1,3,5,7,11,17,23,28]
accuracy_list=[]
for k in k_values:
  predicted_labels=k_nearest_neighbours(k,vectors_train,labels_train,vectors_test)
  accuracy=accuracy_score(labels_test,predicted_labels)
  accuracy_list.append(accuracy)
k_values=np.array(k_values)
accuracy_list=np.array(accuracy_list)

len(vectors)

plt.figure()
plt.figure()
plt.ylim(0, 101)
plt.plot(k_values, accuracy_list)
plt.xlabel("K Value")
plt.ylabel("% Accuracy")
plt.title("KNN Algorithm Accuracy With Different K")
plt.grid()
plt.show()

"""***2. Explain which distance measure works best and why? Explore the distance measures and weigh their pro and cons in different application settings.***

***3. Report Mean Squared Error(MSE), Mean-Absolute-Error(MAE), R-squared (R2) score in a tabular form***
"""



"""***4. Choose different K values (k=1,3,5,7,11,17,23,28) and experiment. Plot a graph showing R2 score vs k.***"""



"""### Train and test Sklearn's KNN classifier model on your data (use metric which gave best results on your experimentation with built-from-scratch model.)"""



"""***Compare both the models result.***"""



"""***What is the time complexity of training using KNN classifier?***

***What is the time complexity while testing? Is KNN a linear classifier or can it learn any boundary?***
"""