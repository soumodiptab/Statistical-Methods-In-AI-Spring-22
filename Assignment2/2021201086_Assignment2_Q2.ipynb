{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "improving-pepper",
   "metadata": {},
   "source": [
    "# Assignment 2 - Question 2\n",
    "The objective of this assignment is to get you familiarize with  the  problem  of  `Linear Regression`.\n",
    "\n",
    "## Instructions\n",
    "- Write your code and analysis in the indicated cells.\n",
    "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
    "- Do not attempt to change the contents of other cells.\n",
    "- No inbuilt functions to be used until specified\n",
    "\n",
    "## Submission\n",
    "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
    "- Rename the notebook to `<roll_number>_Assignment2_Q2.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-transaction",
   "metadata": {},
   "source": [
    "## 2.0 Background about the dataset\n",
    "\n",
    "TLDR: You have 4 independent variables (`float`) for each molecule. You can use a linear combination of these 4 independent variables to predict the bandgap (dependent variable) of each molecule.\n",
    "\n",
    "You can read more about the problem in [Li et al, Bandgap tuning strategy by cations and halide ions of lead halide perovskites learned from machine learning, RSC Adv., 2021,11, 15688-15694](https://doi.org/10.1039/D1RA03117A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lyric-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hundred-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_molecules = list()\n",
    "\n",
    "with open('bg_data.txt', 'r') as infile:\n",
    "    input_rows = csv.DictReader(infile)\n",
    "    \n",
    "    for row in input_rows:\n",
    "        current_mol = ([float(row['Cs']), float(row['FA']), float(row['Cl']), float(row['Br'])], float(row['Bandgap']))\n",
    "        all_molecules.append(current_mol)\n",
    "\n",
    "random.shuffle(all_molecules)\n",
    "\n",
    "\n",
    "num_train = int(len(all_molecules) * 0.8)\n",
    "\n",
    "# each point in x_train has 4 values - 1 for each feature\n",
    "x_train = [x[0] for x in all_molecules[:num_train]]\n",
    "# each point in y_train has 1 value - the bandgap of the molecule\n",
    "y_train = [x[1] for x in all_molecules[:num_train]]\n",
    "\n",
    "x_test = [x[0] for x in all_molecules[num_train:]]\n",
    "y_test = [x[1] for x in all_molecules[num_train:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-direction",
   "metadata": {},
   "source": [
    "### 2.1 Implement a Linear Regression model that minimizes the MSE **without using any libraries**. You may use NumPy to vectorize your code, but *do not use numpy.polyfit* or anything similar.\n",
    "\n",
    "2.1.1 Explain how you plan to implement Linear Regression in 5-10 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-forth",
   "metadata": {},
   "source": [
    "<!-- your answer to 1.1.1 -->\n",
    "* To implement linear regression our main goal would be to find the weights of the regression equation.\n",
    "* The equation would also contain a bias term `w0`. So we need to bias our initial weights to include it.\n",
    "* We are going to use gradient descent to minimize the loss function such that we have least difference between the actual and predicted values.\n",
    "* Here we would be using two hyper parameters `epoch` and `learning_rate` which we will arrive by trial error.\n",
    "* In each iteration we would be finding the partial derivates with respect to each weight and use the `learning_rate` to update the new value of the weights.\n",
    "* `learning_rate` is very important here as it dictates how fast or slow we arrive at our minimum by finding the gradient in each iteration.\n",
    "* We will keep repeating and tuning the parameters until we arrive at a optimum one that can be used in our linear regression function to predict the values of `y` given `x`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-winter",
   "metadata": {},
   "source": [
    "2.1.2 Implement Linear Regression using `x_train` and `y_train` as the train dataset.\n",
    "\n",
    "2.1.2.1 Choose the best learning rate and print the learning rate for which you achieved the best MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6650fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement Linear Regression\n",
    "def biasing(x):\n",
    "    return np.c_[np.ones(len(x)),x]\n",
    "def cost_func(y,y_pred):\n",
    "    sr=np.square(y-y_pred)\n",
    "    return np.mean(sr)/2\n",
    "def gradient_descent(x,y,learning_rate,epochs):\n",
    "    cost=[]\n",
    "    epoch=[]\n",
    "    x_bias=biasing(np.mat(x))\n",
    "    w=np.mat(np.zeros(x_bias.shape[1])).T\n",
    "    y=np.mat(y).T\n",
    "    for e in range(epochs):\n",
    "        y_pred=np.matmul(x_bias,w)\n",
    "        gradient=-1*(np.matmul(x_bias.T,(y-y_pred))/len(x_bias))\n",
    "        w=w-learning_rate*gradient\n",
    "        epoch.append(e+1)\n",
    "        cost.append(cost_func(y,y_pred))\n",
    "    return w,epoch,cost      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f23bcd0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gradient_descent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/soumodiptab/courses/SMAI/Assignment2/2021201086_Assignment2_Q2.ipynb Cell 9'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/soumodiptab/courses/SMAI/Assignment2/2021201086_Assignment2_Q2.ipynb#ch0000008vscode-remote?line=0'>1</a>\u001b[0m weights,epochs,cost\u001b[39m=\u001b[39mgradient_descent(x_train,y_train,\u001b[39m1e-1\u001b[39m,\u001b[39m1000\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/soumodiptab/courses/SMAI/Assignment2/2021201086_Assignment2_Q2.ipynb#ch0000008vscode-remote?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mEpochs\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/soumodiptab/courses/SMAI/Assignment2/2021201086_Assignment2_Q2.ipynb#ch0000008vscode-remote?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mcost\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gradient_descent' is not defined"
     ]
    }
   ],
   "source": [
    "weights,epochs,cost=gradient_descent(x_train,y_train,1e-1,1000)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('cost')\n",
    "plt.plot(epochs,cost)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2972f5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.6317503 ],\n",
       "        [-0.01744744],\n",
       "        [-0.14604204],\n",
       "        [ 1.50243789],\n",
       "        [ 0.59804659]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcbd88be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression\n",
    "def linear_regression(x_train,y_train,x_test,learning_rate=1e-1,epochs=1000):\n",
    "    w_parameters,epoch,cost=gradient_descent(x_train,y_train,learning_rate,epochs)\n",
    "    x=x_bias=biasing(np.mat(x_test))\n",
    "    y_test=np.matmul(x,w_parameters)\n",
    "    return y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb89361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=linear_regression(x_train,y_train,x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-tampa",
   "metadata": {},
   "source": [
    "2.1.3 Make a [Parity Plot](https://en.wikipedia.org/wiki/Parity_plot) of your model's bandgap predictions on the test set with the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "foster-center",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the predictions of x_test into `y_pred`\n",
    "\n",
    "#\n",
    "# ...\n",
    "#\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(10,20))\n",
    "\n",
    "ax.scatter(y_test, y_pred)\n",
    "\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "]\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "\n",
    "ax.set_title('Parity Plot of Custom Linear Regression')\n",
    "ax.set_xlabel('Ground truth bandgap values')\n",
    "ax.set_ylabel('Predicted bandgap values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-chaos",
   "metadata": {},
   "source": [
    "### 2.2 Implement Ridge regression\n",
    "2.2.1 Explain Ridge regression briefly in 1-2 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b0e844",
   "metadata": {},
   "source": [
    "Ridge regression is a regularization technique used to tune our linear regression model that is used to analyse any data that suffers from multicollinearity. This method performs L2 regularization. When we face tbe issue of multicollinearity, least-squares are unbiased, and variances are large, this results in predicted values being far away from the actual values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-forwarding",
   "metadata": {},
   "source": [
    "2.2.2 Implement Ridge regression and make a table of different RMSE scores you achieved with different values of alpha. What does the parameter `alpha` do? How does it affect the results here? Explain in 5-10 lines in total. (You can use scikit-learn from this cell onwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "violent-northern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>0.054319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.054319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.054319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.054318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>0.054309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.054222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.054319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.068291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.149718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.201012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.252860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           alpha      RMSE\n",
       "0   1.000000e-15  0.054319\n",
       "1   1.000000e-10  0.054319\n",
       "2   1.000000e-08  0.054319\n",
       "3   1.000000e-04  0.054318\n",
       "4   1.000000e-03  0.054309\n",
       "5   1.000000e-02  0.054222\n",
       "6   0.000000e+00  0.054319\n",
       "7   1.000000e+00  0.068291\n",
       "8   5.000000e+00  0.149718\n",
       "9   1.000000e+01  0.201012\n",
       "10  2.000000e+01  0.252860"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you should not have imported sklearn before this point\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# implement Ridge regression and make a table where you explore the effect of different values of `alpha`\n",
    "alphas = [1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2,0, 1, 5, 10, 20]\n",
    "rmses=[]\n",
    "for a in alphas:\n",
    "    model=Ridge(alpha=a)\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    rmse=mean_squared_error(y_test, y_pred, squared=False)\n",
    "    rmses.append(rmse)\n",
    "df=pd.DataFrame(list(zip(alphas,rmses)),columns=['alpha','RMSE'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e856cb",
   "metadata": {},
   "source": [
    "#### Ans. Explaination\n",
    "RMSE or Root Mean Squared Error measures the average magnitude of the residuals or error.Here the Alpha value represents the amount by which we want to penalize the model to make it more generic( i.e. underfit). \n",
    "\n",
    "The value of alpha typically ranges from 0 - infinity. Higher the alpha coefficient, more generic our model. If the alpha value is very less then the model performs similarly to normal linear regression model. From the above table we can see that with decreasing alpha values the model becomes more accurate and RMSE score decreases. This is due to the fact that the particular dataset we are working on is very simple, so overfitting is very unlikely. Thus increasing the alpha values do not increase the RMSE score. In Ridge Regression, we can see that as the values of alpha increases, RMSE also increases, this is because Ridge Regression tends to make the weights of the parameters close to 0 rather than making it absolutely 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-temperature",
   "metadata": {},
   "source": [
    "### 2.3 Implement Lasso regression\n",
    "2.3.1 Explain Lasso regression briefly in 1-2 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a84cc77",
   "metadata": {},
   "source": [
    "Lasso regression, or the Least Absolute Shrinkage and Selection Operator, is also a modification of linear regression.It performs L1 regulariation which adds a penalty equal to the absolute value of the magnitude of coefficients. This type of regularization can result in sparse models with few coefficients. Some coefficients can become zero and eliminated from the model. Larger penalties result in coefficient values closer to zero, which is the ideal for producing simpler models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-wonder",
   "metadata": {},
   "source": [
    "2.3.2 Implement Lasso regression and make a table of different RMSE scores you achieved with different values of alpha. What does the parameter `alpha` do? How does it affect the results here? Explain in 5-10 lines in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "extra-brighton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-15</td>\n",
       "      <td>0.054319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.054319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.054319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.054318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>0.054309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.054222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.054319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.068291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.149718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.201012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alpha      RMSE\n",
       "0  1.000000e-15  0.054319\n",
       "1  1.000000e-10  0.054319\n",
       "2  1.000000e-08  0.054319\n",
       "3  1.000000e-04  0.054318\n",
       "4  1.000000e-03  0.054309\n",
       "5  1.000000e-02  0.054222\n",
       "6  1.000000e+00  0.054319\n",
       "7  5.000000e+00  0.068291\n",
       "8  1.000000e+01  0.149718\n",
       "9  2.000000e+01  0.201012"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement Lasso regression and make a table where you explore the effect of different values of `alpha`\n",
    "from sklearn.linear_model import Lasso\n",
    "alphas = [1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]\n",
    "for a in alphas:\n",
    "    model=Lasso(alpha=a)\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    rmse=mean_squared_error(y_test, y_pred, squared=False)\n",
    "    rmses.append(rmse)\n",
    "df=pd.DataFrame(list(zip(alphas,rmses)),columns=['alpha','RMSE'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d903813",
   "metadata": {},
   "source": [
    "#### Ans. Explaination\n",
    "RMSE or Root Mean Squared Error measures the average magnitude of the residuals or error.Here the Alpha value represents the amount by which we want to penalize the model to make it more generic( i.e. underfit). \n",
    "\n",
    "The value of alpha typically ranges from 0 - infinity. Higher the alpha coefficient, more generic our model. If the alpha value is very less then the model performs similarly to normal linear regression model. From the above table we can see that with decreasing alpha values the model becomes more accurate and RMSE score decreases. This is due to the fact that the particular dataset we are working on is very simple, so overfitting is very unlikely. Thus increasing the alpha values do not increase the RMSE score. In Lasso Regression, we can see that as the values of alpha increases, RMSE also increases, this is because Ridge Regression tends to make the weights of the parameters close to 0 rather than making it absolutely 0. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
